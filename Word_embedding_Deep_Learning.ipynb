{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubh9956/Deep-Learning/blob/main/Word_embedding_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''here I have imported the important libraries in keras and numpy and then \n",
        "I'm going to do the food review classification I have like 10 reviews here very simple data set and then 10 labels\n",
        "so the first five are positive reviews you can figure it out and the next five are negative reviews'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "twfbiYD34p7A",
        "outputId": "a94b224b-a6b8-4d4d-b351-27c0f100c625"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"here I have imported the important libraries in keras and numpy and then \\nI'm going to do the food review classification I have like 10 reviews here very simple data set and then 10 labels\\nso the first five are positive reviews you can figure it out and the next five are negative reviews\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "reviews = ['nice food',\n",
        "        'amazing restaurant',\n",
        "        'too good',\n",
        "        'just loved it!',\n",
        "        'will go again',\n",
        "        'horrible food',\n",
        "        'never go there',\n",
        "        'poor service',\n",
        "        'poor quality',\n",
        "        'needs improvement']\n",
        "\n",
        "sentiment = np.array([1,1,1,1,1,0,0,0,0,0])"
      ],
      "metadata": {
        "id": "5X7NL8us0xtF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''so the first thing we're going to do here is we'll convert that into a one hot vector so there is a\n",
        "method called one hot and what that method will do is it takes the review and then you specify your vocabulary size \n",
        "size so let's say if you say 30 it will give\n",
        "a unique numbers so here it gives 3 number to amazing and 18 to restaurent so the number\n",
        "will be between\n",
        "1 to 30. \n",
        "If i say 500 the max number will be 500 basically here we get 304 and 127\n",
        "so after one hot encoding we are getting a fixed unique number and internally keras that the layer will\n",
        "convert it to 0 0 1 1 and so'''\n"
      ],
      "metadata": {
        "id": "ljifCWG25Y--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot(\"amazing restaurant\",30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9-KS68i0x0D",
        "outputId": "6fa57016-0609-4287-c59f-d4932a5ad56f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 17]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot(\"amazing restaurant\",500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OtwF2c76aQ3",
        "outputId": "36dffade-0177-4265-928a-67bffacc7f9d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[235, 82]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''initialize vocabulary size let's say my vocab size is 30. Now i want to encode all these\n",
        " reviews as same i did for amazing restaurant,  for each review I created encoded vector'''"
      ],
      "metadata": {
        "id": "oH9n5rjt9USg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 30                                   \n",
        "encoded_reviews = [one_hot(d, vocab_size) for d in reviews]\n",
        "print(encoded_reviews)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aTNLY8B0x3C",
        "outputId": "78529702-b356-4e09-905f-91fcc32d99e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[25, 18], [4, 17], [26, 24], [18, 26, 1], [9, 2, 23], [4, 18], [11, 2, 12], [24, 24], [24, 11], [22, 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 3\n",
        "padded_reviews = pad_sequences(encoded_reviews, maxlen=max_length, padding='post') #padding post means pair the reviews towards the end so now see towards the end I get zeros\n",
        "print(padded_reviews)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBMP_J580x53",
        "outputId": "1093d2ea-bea4-494d-b1bb-1b79711e5cc4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[25 18  0]\n",
            " [ 4 17  0]\n",
            " [26 24  0]\n",
            " [18 26  1]\n",
            " [ 9  2 23]\n",
            " [ 4 18  0]\n",
            " [11  2 12]\n",
            " [24 24  0]\n",
            " [24 11  0]\n",
            " [22  3  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''my model is what like sequential okay and then i need to add my first layer so my first layer  will be embedding layer  \n",
        "for that I have already imported embedding class and the way embedding class works is it takes a couple of argument okay so what \n",
        "is the first argument the first argument is vocab size then the second argument is the vector size my model is what like sequential okay \n",
        "and then i need to add my first layer so my first layer  will be embedding layer  for that I have already imported embedding class and the \n",
        "way embedding class works is it takes a couple of argument okay so what is the first argument the first argument\n",
        "is vocab size then the second argument is the vector size so vocabulary size is 30 then my vector size after the vector size you will \n",
        "supply the length so max length is 3 and I need to give it a name so that I can use it later'''"
      ],
      "metadata": {
        "id": "iOPszLBF_hr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeded_vector_size = 4\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embeded_vector_size, input_length=max_length,name=\"embedding\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "LDakXcTM0x82"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''The second layer again if you look at the diagram once you get embedding vectors these vectors\n",
        "from your embedding layer you want to\n",
        "flatten them to create this particular vector \n",
        "the layer after that is one neuron sigmoid activation function so it will be a dense layer with a sigma activation\n",
        "now just to make it more convenient my x is padded reviews and y sentiment correct\n",
        "this is my x training samples and this is my labels y so just to make it easy I'm just putting them in a different variable called x and y\n",
        "and I will now compile my model \n"
      ],
      "metadata": {
        "id": "1du2d3qDP3PJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_reviews\n",
        "y = sentiment\n"
      ],
      "metadata": {
        "id": "EerM3onb0x_r"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''usually we end up using adam as an optimizer and binary cross entropy because the output is either one\n",
        "or zero right like the review is positive or negative that's why binary cross entropy\n",
        "and then you can print when you run it see the embedding vector size is four the max sentence length is three all\n",
        "right once you do flatten you will get twelve 12 '''\n"
      ],
      "metadata": {
        "id": "xH9fDeXtR7yQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dFscbOa0yC3",
        "outputId": "800786b1-c4de-47eb-dc6b-311b4f1d52c9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 3, 4)              120       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133\n",
            "Trainable params: 133\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=50, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q38_z3x80yGM",
        "outputId": "93d8a93e-6e21-4035-998f-9dcbbe50a176"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f84011453d0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "loss, accuracy = model.evaluate(X, y)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVJwz2NK0yMD",
        "outputId": "8714abb8-b0a7-4bc1-b8f6-6f7d8b3e4411"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 107ms/step - loss: 0.6352 - accuracy: 0.9000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8999999761581421"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = model.get_layer('embedding').get_weights()[0]\n",
        "len(weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qfts5FPB0yPE",
        "outputId": "623a6ae5-4f06-402f-98e1-b68c68fdd3f3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights[13]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNhu-P4m0yR5",
        "outputId": "ff4b5d10-e51d-4178-e74d-61f72019b18f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.04224786, -0.0399904 ,  0.04945857,  0.02715309], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights[4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0o2oS910yXb",
        "outputId": "ded13ee4-11c2-4816-a7bf-33c4ad29bf04"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.0024863 , -0.00578571, -0.06843247, -0.07322812], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights[16]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ai8OUoT1b-e",
        "outputId": "e9d95cb8-6e91-4bf9-c834-c0a6b95e9993"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.04884008,  0.01270571, -0.04317185,  0.01137583], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tSt-3AijX8dy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}